{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f86cd97-3c73-4bb3-94af-2b1abe9f0d76",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Sp3', 'Sp4', 'Sp7', 'Sp9', 'Sp11', 'Sp12', 'Sp13', 'Sp14', 'Sp15', 'Sp17', 'Sp19', 'Sp21'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m entrained_spiders\n\u001b[1;32m    103\u001b[0m all_columns_to_keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(columns_to_keep)\n\u001b[0;32m--> 104\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_columns_to_keep\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Use merged_df here, not entrained_spiders\u001b[39;00m\n\u001b[1;32m    106\u001b[0m finaldf\u001b[38;5;241m.\u001b[39mappend(filtered_df)\n\u001b[1;32m    108\u001b[0m merged_dfx \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(finaldf)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Sp3', 'Sp4', 'Sp7', 'Sp9', 'Sp11', 'Sp12', 'Sp13', 'Sp14', 'Sp15', 'Sp17', 'Sp19', 'Sp21'] not in index\""
     ]
    }
   ],
   "source": [
    "#FUNCTION TO CLEAN A SINGLE DF\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "\n",
    "for i in range(1, 33):\n",
    "    col_names.append(f\"Sp{i}\")\n",
    "\n",
    "file = 'Steatoda A masking midnight.txt'\n",
    "\n",
    "df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "df = df.set_index('Index')\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "\n",
    "#df.to_csv('steatodaA.csv')\n",
    "\n",
    "#FUNCTION TO FILTER THRESHOLD ON A SINGLE FILE\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_merge(df, threshold=0):\n",
    "    additional_columns = df.columns[:3]\n",
    "    filtered_dfs = []\n",
    "\n",
    "    for day in range(1, 9):  \n",
    "        day_df = df[df['Day'] == day] \n",
    "        count_mov = day_df.filter(like=\"Sp\")  \n",
    "        x = count_mov.sum(axis=0)  \n",
    "        z = x > threshold  \n",
    "        columns_to_keep = z[z].index \n",
    "        \n",
    "        all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "        filtered_df = day_df[all_columns_to_keep]\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    merged_df = pd.concat(filtered_dfs)\n",
    "    merged_df1 = merged_df.dropna(axis=1)\n",
    "    \n",
    "    return merged_df1\n",
    "    \n",
    "merged_df = filter_and_merge(df)\n",
    "\n",
    "#CODE TO TEST FOR ENTRAINMENT\n",
    "\n",
    "def entrainment(data, column):\n",
    "    if column not in data.columns:\n",
    "        return False\n",
    "    \n",
    "    dflight = data[data['Light'] == 1][column]\n",
    "    dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "    lightmean = np.mean(dflight)\n",
    "    darkmean = np.mean(dfdark)\n",
    "    \n",
    "    if darkmean == 0:\n",
    "        return False\n",
    "    \n",
    "    diff = lightmean / darkmean\n",
    "    return diff > 0.25\n",
    "\n",
    "spiders = [\"Sp\"+str(i) for i in range(1, 33)]\n",
    "\n",
    "entrainment_results = []\n",
    "\n",
    "for spider_column in spiders:\n",
    "    if spider_column in merged_df.columns:  # Check if the column exists\n",
    "        entrainment_result = entrainment(merged_df, spider_column)\n",
    "        entrainment_results.append((spider_column, entrainment_result))\n",
    "\n",
    "results_df = pd.DataFrame(entrainment_results, columns=['Spider', 'Entrained'])\n",
    "\n",
    "entrained_spiders = results_df[results_df['Entrained'] == True]['Spider'].tolist()\n",
    "\n",
    "#CODE TO FILTER ENTRAINMENT\n",
    "finaldf = []\n",
    "\n",
    "additional_columns = results_df.columns[:3]\n",
    "columns_to_keep = entrained_spiders\n",
    "        \n",
    "all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "filtered_df = results_df[all_columns_to_keep]  # Use merged_df here, not entrained_spiders\n",
    "\n",
    "finaldf.append(filtered_df)\n",
    "\n",
    "merged_dfx = pd.concat(finaldf)\n",
    "merged_dfx1 = merged_dfx.dropna(axis=1)  # Use merged_dfx here, not merged_df\n",
    "\n",
    "display(merged_dfx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67d71a50-d5be-4eab-9f54-e6b079114814",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Spider'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m entrained_spiders\n\u001b[1;32m     97\u001b[0m all_columns_to_keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(columns_to_keep)\n\u001b[0;32m---> 98\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_columns_to_keep\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    100\u001b[0m finaldf\u001b[38;5;241m.\u001b[39mappend(filtered_df)\n\u001b[1;32m    102\u001b[0m merged_dfx \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(finaldf)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Spider'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define column names\n",
    "col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "for i in range(1, 33):\n",
    "    col_names.append(f\"Sp{i}\")\n",
    "\n",
    "# Read and preprocess the data\n",
    "file = 'Steatoda A masking midnight.txt'\n",
    "df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "df = df.set_index('Index')\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "# Convert Dates\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "# Combine Date and Time\n",
    "df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                 month=df['Date'].dt.month,\n",
    "                                 day=df['Date'].dt.day,\n",
    "                                 hour=df['Time'].dt.hour,\n",
    "                                 minute=df['Time'].dt.minute,\n",
    "                                 second=df['Time'].dt.second))\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "# Add a 'Day' column\n",
    "day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "\n",
    "# Function to filter and merge data based on threshold\n",
    "def filter_and_merge(df, threshold=0):\n",
    "    additional_columns = df.columns[:3]\n",
    "    filtered_dfs = []\n",
    "\n",
    "    for day in range(1, 9):  \n",
    "        day_df = df[df['Day'] == day] \n",
    "        count_mov = day_df.filter(like=\"Sp\")  \n",
    "        x = count_mov.sum(axis=0)  \n",
    "        z = x > threshold  \n",
    "        columns_to_keep = z[z].index \n",
    "        \n",
    "        all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "        filtered_df = day_df[all_columns_to_keep]\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    merged_df = pd.concat(filtered_dfs)\n",
    "    merged_df1 = merged_df.dropna(axis=1)\n",
    "    \n",
    "    return merged_df1\n",
    "    \n",
    "merged_df = filter_and_merge(df)\n",
    "\n",
    "# Function to test for entrainment\n",
    "def entrainment(data, column):\n",
    "    if column not in data.columns:\n",
    "        return False\n",
    "    \n",
    "    dflight = data[data['Light'] == 1][column]\n",
    "    dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "    lightmean = np.mean(dflight)\n",
    "    darkmean = np.mean(dfdark)\n",
    "    \n",
    "    if darkmean == 0:\n",
    "        return False\n",
    "    \n",
    "    diff = lightmean / darkmean\n",
    "    return diff > 0.25\n",
    "\n",
    "# Check for entrainment across all spiders\n",
    "spiders = [\"Sp\"+str(i) for i in range(1, 33)]\n",
    "entrainment_results = []\n",
    "\n",
    "for spider_column in spiders:\n",
    "    if spider_column in merged_df.columns:\n",
    "        entrainment_result = entrainment(merged_df, spider_column)\n",
    "        entrainment_results.append((spider_column, entrainment_result))\n",
    "\n",
    "results_df = pd.DataFrame(entrainment_results, columns=['Spider', 'Entrained'])\n",
    "entrained_spiders = results_df[results_df['Entrained'] == True]['Spider'].tolist()\n",
    "\n",
    "# Filter for entrainment\n",
    "finaldf = []\n",
    "\n",
    "additional_columns = results_df.columns[:1]\n",
    "columns_to_keep = entrained_spiders\n",
    "        \n",
    "all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "filtered_df = merged_df[all_columns_to_keep]\n",
    "\n",
    "finaldf.append(filtered_df)\n",
    "\n",
    "merged_dfx = pd.concat(finaldf)\n",
    "merged_dfx1 = merged_dfx.dropna(axis=1)\n",
    "\n",
    "# Display the final dataframe with entrained spiders\n",
    "print(merged_dfx1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1158aa70-a5ef-4243-bded-9e2d2336ab32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>Light</th>\n",
       "      <th>Sp3</th>\n",
       "      <th>Sp4</th>\n",
       "      <th>Sp7</th>\n",
       "      <th>Sp9</th>\n",
       "      <th>Sp10</th>\n",
       "      <th>Sp11</th>\n",
       "      <th>Sp12</th>\n",
       "      <th>Sp13</th>\n",
       "      <th>Sp14</th>\n",
       "      <th>Sp15</th>\n",
       "      <th>Sp17</th>\n",
       "      <th>Sp19</th>\n",
       "      <th>Sp21</th>\n",
       "      <th>Sp25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-17 15:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-17 15:57:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-17 15:58:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-17 15:59:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-17 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10036</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-24 14:58:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-24 14:59:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10038</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-24 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-24 15:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10040</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-24 15:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10027 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Day                Time  Light  Sp3  Sp4  Sp7  Sp9  Sp10  Sp11  Sp12  \\\n",
       "Index                                                                         \n",
       "14       1 2024-04-17 15:56:00      1    0   16    2    0     0     0    26   \n",
       "15       1 2024-04-17 15:57:00      1    0    8    3    0     0     0    17   \n",
       "16       1 2024-04-17 15:58:00      1    0    8    4    0     1     0    19   \n",
       "17       1 2024-04-17 15:59:00      1    0   15    2    0     3     0    11   \n",
       "18       1 2024-04-17 16:00:00      1    0    9    2    0     0     0    14   \n",
       "...    ...                 ...    ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "10036    8 2024-04-24 14:58:00      1    0    0    0    0     0     0     0   \n",
       "10037    8 2024-04-24 14:59:00      1    0    0    0    0     0     0     0   \n",
       "10038    8 2024-04-24 15:00:00      1    0    0    0    0     0     0     0   \n",
       "10039    8 2024-04-24 15:01:00      1    0    0    0    0     0     0     0   \n",
       "10040    8 2024-04-24 15:02:00      1    0    0    0    0     0     0     0   \n",
       "\n",
       "       Sp13  Sp14  Sp15  Sp17  Sp19  Sp21  Sp25  \n",
       "Index                                            \n",
       "14        0     0     0     0     2     0     0  \n",
       "15        0     0     0     0     1     0     0  \n",
       "16        0     0     0     0     6     0     0  \n",
       "17        0     0     0     0     1     0     0  \n",
       "18        6     0     0     0     4     0     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...  \n",
       "10036     0     0     0     0     0     0     0  \n",
       "10037     0     0     0     0     0     0     0  \n",
       "10038     0     0     0     0     0     0     0  \n",
       "10039     0     0     0     0     0     0     0  \n",
       "10040     0     0     0     0     0     0     0  \n",
       "\n",
       "[10027 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#FUNCTION TO FILTER THRESHOLD ON A SINGLE FILE\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_merge(df, threshold=0):\n",
    "    additional_columns = df.columns[:3]\n",
    "    filtered_dfs = []\n",
    "\n",
    "    for day in range(1, 9):  \n",
    "        day_df = df[df['Day'] == day] \n",
    "        count_mov = day_df.filter(like=\"Sp\")  \n",
    "        x = count_mov.sum(axis=0)  \n",
    "        z = x > threshold  \n",
    "        columns_to_keep = z[z].index \n",
    "        \n",
    "        all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "        filtered_df = day_df[all_columns_to_keep]\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    merged_df = pd.concat(filtered_dfs)\n",
    "    merged_df1 = merged_df.dropna(axis=1)\n",
    "    \n",
    "    return merged_df1\n",
    "    \n",
    "merged_df = filter_and_merge(df)\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30cd9d56-9a42-4145-8471-dac4c49e13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE TO TEST FOR ENTRAINMENT\n",
    "import numpy as np\n",
    "\n",
    "def entrainment(data, column):\n",
    "    if column not in data.columns:\n",
    "        return False\n",
    "    \n",
    "    dflight = data[data['Light'] == 1][column]\n",
    "    dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "    lightmean = np.mean(dflight)\n",
    "    darkmean = np.mean(dfdark)\n",
    "    \n",
    "    if darkmean == 0:\n",
    "        return False\n",
    "    \n",
    "    diff = lightmean / darkmean\n",
    "    return diff > 0.25\n",
    "\n",
    "spiders = [\"Sp\"+str(i) for i in range(1, 33)]\n",
    "\n",
    "entrainment_results = []\n",
    "\n",
    "for spider_column in spiders:\n",
    "    if spider_column in merged_df.columns:  # Check if the column exists\n",
    "        entrainment_result = entrainment(merged_df, spider_column)\n",
    "        entrainment_results.append((spider_column, entrainment_result))\n",
    "\n",
    "results_df = pd.DataFrame(entrainment_results, columns=['Spider', 'Entrained'])\n",
    "\n",
    "entrained_spiders = results_df[results_df['Entrained'] == True]['Spider'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf7ba4-018c-42e6-b067-88a6ac6ebf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE TO FILTER ENTRAINMENT\n",
    "finaldf = []\n",
    "\n",
    "additional_columns = merged_df.columns[:3]  # Assuming the first three columns are additional columns\n",
    "columns_to_keep = entrained_spiders\n",
    "        \n",
    "all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "filtered_df = merged_df[all_columns_to_keep]  # Use merged_df here, not entrained_spiders\n",
    "\n",
    "finaldf.append(filtered_df)\n",
    "\n",
    "merged_dfx = pd.concat(finaldf)\n",
    "merged_dfx1 = merged_dfx.dropna(axis=1)  # Use merged_dfx here, not merged_df\n",
    "\n",
    "display(merged_dfx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3789c821-fbca-45a7-bc97-7488749525b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m dayfourfive\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# filter time (2 pm - 4 pm in this case) - fix this because is about 2 hours but not exactly 2 hours (look if light or dark)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mdayfourfive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdayfourfive\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-03-23 14:00:00\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m index1 \u001b[38;5;241m=\u001b[39m dayfourfive\u001b[38;5;241m.\u001b[39mloc[(dayfourfive \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-03-23 16:00:00\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m index2 \u001b[38;5;241m=\u001b[39m dayfourfive\u001b[38;5;241m.\u001b[39mloc[(dayfourfive \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-03-24 14:00:00\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:5366\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5364\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[1;32m   5365\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key)\n\u001b[0;32m-> 5366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   5369\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5370\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m   5371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_slice(key)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#filter day 5 and day 4 (the nile research did day the day of pulse and the day before)\n",
    "#I can also filter all days without pulse and average them and compare with the day WITH pulse \n",
    "dayfour = df.loc[df['Day'] == 4]\n",
    "dayfive = df.loc[df['Day'] == 5]\n",
    "dayfourfive = pd.concat([dayfour, dayfive])\n",
    "dayfourfive\n",
    "# filter time (2 pm - 4 pm in this case) - fix this because is about 2 hours but not exactly 2 hours (look if light or dark)\n",
    "index = dayfourfive.loc[(dayfourfive == '2024-03-23 14:00:00').any(axis=1)].index[0]\n",
    "index1 = dayfourfive.loc[(dayfourfive == '2024-03-23 16:00:00').any(axis=1)].index[0]\n",
    "\n",
    "index2 = dayfourfive.loc[(dayfourfive == '2024-03-24 14:00:00').any(axis=1)].index[0]\n",
    "index3 = dayfourfive.loc[(dayfourfive == '2024-03-24 16:00:00').any(axis=1)].index[0]\n",
    "\n",
    "dayfourslice = dayfourfive.loc[index:index1, :]\n",
    "dayfiveslice = dayfourfive.loc[index2:index3, :]\n",
    "\n",
    "twotofourslice = pd.concat([dayfourslice, dayfiveslice])\n",
    "# filter individual spider \n",
    "spider1_day4 = dayfourslice['Sp21']\n",
    "spider1_day5 = dayfiveslice['Sp21']\n",
    "\n",
    "# average it out for both pulse and no pulse \n",
    "meanday4 = spider1_day4.mean()\n",
    "meanday5 = spider1_day5.mean()\n",
    "days = ['Pre-pulse day', '2-hour pulse']\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(3,3))\n",
    "\n",
    "plt.bar(days, [meanday4, meanday5]) \n",
    "\n",
    "plt.suptitle('Comparison in activity with and without the 2 hour pulse', fontsize=8)\n",
    "plt.ylabel('Average activity between 2 pm and 4 pm', fontsize=8)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66ad28-4a48-4223-b6d7-8511f19d0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_compare_activity(df, spider_col, day_pulse, day_pre_pulse, start_hour, end_hour):\n",
    "    pre_pulse_date = df.loc[df['Day'] == day_pre_pulse, 'Time'].dt.date.unique()[0]\n",
    "    pulse_date = df.loc[df['Day'] == day_pulse, 'Time'].dt.date.unique()[0]\n",
    "    \n",
    "    start_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {start_hour}\")\n",
    "    end_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {end_hour}\")\n",
    "    start_time_pulse = pd.to_datetime(f\"{pulse_date} {start_hour}\")\n",
    "    end_time_pulse = pd.to_datetime(f\"{pulse_date} {end_hour}\")\n",
    "    \n",
    "    day_pre = df.loc[df['Day'] == day_pre_pulse]\n",
    "    day_pulse = df.loc[df['Day'] == day_pulse]\n",
    "    \n",
    "    day_pre_filtered = day_pre[(day_pre['Time'] >= start_time_pre_pulse) & (day_pre['Time'] <= end_time_pre_pulse)]\n",
    "    day_pulse_filtered = day_pulse[(day_pulse['Time'] >= start_time_pulse) & (day_pulse['Time'] <= end_time_pulse)]\n",
    "    \n",
    "    spider_day_pre = day_pre_filtered[spider_col]\n",
    "    spider_day_pulse = day_pulse_filtered[spider_col]\n",
    "    \n",
    "    mean_day_pre = spider_day_pre.mean()\n",
    "    mean_day_pulse = spider_day_pulse.mean()\n",
    "    \n",
    "    means_df = pd.DataFrame({\n",
    "        'Day': ['Pre-pulse day', '2-hour pulse'],\n",
    "        'Mean Activity': [mean_day_pre, mean_day_pulse]\n",
    "    })\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.bar(means_df['Day'], means_df['Mean Activity'])\n",
    "    plt.suptitle('Comparison in activity with and without the 2-hour pulse', fontsize=8)\n",
    "    plt.ylabel('Average activity between {} and {}'.format(start_hour, end_hour), fontsize=6)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.show()\n",
    "    \n",
    "    return means_df\n",
    "\n",
    "spider_col = 'Sp15'  \n",
    "day_pulse = 5 \n",
    "day_pre_pulse = 4  \n",
    "start_hour = '14:00:00' \n",
    "end_hour = '16:00:00'  \n",
    "\n",
    "merged_df['Time'] = pd.to_datetime(merged_df['Time'])\n",
    "\n",
    "means_df = filter_and_compare_activity(merged_df, spider_col, day_pulse, day_pre_pulse, start_hour, end_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3096570-eadf-4933-8b34-dd2007b4cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_compare_activity(df, spider_col, day_pulse, day_pre_pulse, start_hour, end_hour):\n",
    "    # Define the range of days for the pre-pulse period\n",
    "    pre_pulse_days = [2, 3, 4]\n",
    "\n",
    "    # Get the unique dates for the specified days\n",
    "    pre_pulse_dates = df.loc[df['Day'].isin(pre_pulse_days), 'Time'].dt.date.unique()\n",
    "    pulse_date = df.loc[df['Day'] == day_pulse, 'Time'].dt.date.unique()[0]\n",
    "    \n",
    "    # Construct start and end times with the correct dates\n",
    "    start_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_dates[0]} {start_hour}\")\n",
    "    end_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_dates[-1]} {end_hour}\")\n",
    "    start_time_pulse = pd.to_datetime(f\"{pulse_date} {start_hour}\")\n",
    "    end_time_pulse = pd.to_datetime(f\"{pulse_date} {end_hour}\")\n",
    "    \n",
    "    # Filter the days\n",
    "    days_pre_pulse = df.loc[df['Day'].isin(pre_pulse_days)]\n",
    "    day_pulse = df.loc[df['Day'] == day_pulse]\n",
    "    \n",
    "    # Filter the time range for the specified days\n",
    "    day_pre_pulse_filtered = days_pre_pulse[(days_pre_pulse['Time'] >= start_time_pre_pulse) & (days_pre_pulse['Time'] <= end_time_pre_pulse)]\n",
    "    day_pulse_filtered = day_pulse[(day_pulse['Time'] >= start_time_pulse) & (day_pulse['Time'] <= end_time_pulse)]\n",
    "    \n",
    "    # Calculate the mean activity\n",
    "    mean_day_pre_pulse = day_pre_pulse_filtered[spider_col].mean()\n",
    "    mean_day_pulse = day_pulse_filtered[spider_col].mean()\n",
    "    \n",
    "    means_df = pd.DataFrame({\n",
    "        'Day': ['Pre-pulse days 2-4', '2-hour pulse'],\n",
    "        'Mean Activity': [mean_day_pre_pulse, mean_day_pulse]\n",
    "    })\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.bar(means_df['Day'], means_df['Mean Activity'])\n",
    "    plt.suptitle('Comparison in activity with and without the 2-hour pulse', fontsize=10)\n",
    "    plt.ylabel('Average activity between {} and {}'.format(start_hour, end_hour), fontsize=7)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.show()\n",
    "    \n",
    "    return means_df\n",
    "\n",
    "# Example usage\n",
    "spider_col = 'Sp15'  \n",
    "day_pulse = 5 \n",
    "day_pre_pulse = 4  \n",
    "start_hour = '00:00:00' \n",
    "end_hour = '02:00:00'  \n",
    "\n",
    "# Ensure 'Time' is in datetime format\n",
    "merged_df['Time'] = pd.to_datetime(merged_df['Time'])\n",
    "\n",
    "means_df = filter_and_compare_activity(merged_df, spider_col, day_pulse, day_pre_pulse, start_hour, end_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f06e9-e7ae-4f17-aac6-cf00ece9faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_compare_activity(df, day_pulse, day_pre_pulse, start_hour, end_hour):\n",
    "    # Get the unique dates for the specified days\n",
    "    pre_pulse_date = df.loc[df['Day'] == day_pre_pulse, 'Time'].dt.date.unique()[0]\n",
    "    pulse_date = df.loc[df['Day'] == day_pulse, 'Time'].dt.date.unique()[0]\n",
    "    \n",
    "    # Construct start and end times with the correct dates\n",
    "    start_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {start_hour}\")\n",
    "    end_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {end_hour}\")\n",
    "    start_time_pulse = pd.to_datetime(f\"{pulse_date} {start_hour}\")\n",
    "    end_time_pulse = pd.to_datetime(f\"{pulse_date} {end_hour}\")\n",
    "    \n",
    "    # Filter the days\n",
    "    day_pre = df.loc[df['Day'] == day_pre_pulse]\n",
    "    day_pulse = df.loc[df['Day'] == day_pulse]\n",
    "    \n",
    "    # Filter the time range for the specified days\n",
    "    day_pre_filtered = day_pre[(day_pre['Time'] >= start_time_pre_pulse) & (day_pre['Time'] <= end_time_pre_pulse)]\n",
    "    day_pulse_filtered = day_pulse[(day_pulse['Time'] >= start_time_pulse) & (day_pulse['Time'] <= end_time_pulse)]\n",
    "    \n",
    "    # Initialize a list to store mean activity data for each spider\n",
    "    spider_means = []\n",
    "    \n",
    "    # Loop through each spider column\n",
    "    spider_columns = [col for col in df.columns if col.startswith('Sp')]\n",
    "    \n",
    "    # Calculate the number of rows and columns for the grid\n",
    "    num_spiders = len(spider_columns)\n",
    "    num_cols = 3  # You can adjust this value based on how many columns you want in the grid\n",
    "    num_rows = (num_spiders + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array to easily index it\n",
    "    \n",
    "    for idx, spider_col in enumerate(spider_columns):\n",
    "        # Filter for the specific spider column\n",
    "        spider_day_pre = day_pre_filtered[spider_col]\n",
    "        spider_day_pulse = day_pulse_filtered[spider_col]\n",
    "        \n",
    "        # Calculate the mean activity\n",
    "        mean_day_pre = spider_day_pre.mean()\n",
    "        mean_day_pulse = spider_day_pulse.mean()\n",
    "        \n",
    "        # Append the results to the spider_means list\n",
    "        spider_means.append((spider_col, mean_day_pre, mean_day_pulse))\n",
    "        \n",
    "        # Plot the results for each spider in the grid\n",
    "        ax = axes[idx]\n",
    "        days = ['Pre-pulse day', '2-hour pulse']\n",
    "        means = [mean_day_pre, mean_day_pulse]\n",
    "        \n",
    "        ax.bar(days, means)\n",
    "        ax.set_title(f'{spider_col}', fontsize=10)\n",
    "        ax.set_ylabel('Average activity', fontsize=8)\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(days, fontsize=8)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "    \n",
    "    # Remove any empty subplots\n",
    "    for j in range(idx + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a DataFrame to store the means for all spiders\n",
    "    means_df = pd.DataFrame(spider_means, columns=['Spider', 'Mean Pre-pulse Activity', 'Mean Pulse Activity'])\n",
    "    \n",
    "    return means_df\n",
    "\n",
    "# Example usage\n",
    "# Define the parameters\n",
    "day_pulse = 5  # The day when the pulse occurred\n",
    "day_pre_pulse = 4  # The day before the pulse\n",
    "start_hour = '14:00:00'  # Replace with the desired start hour\n",
    "end_hour = '16:00:00'  # Replace with the desired end hour\n",
    "\n",
    "# Ensure 'Time' is in datetime format\n",
    "merged_dfx1['Time'] = pd.to_datetime(merged_dfx1['Time'])\n",
    "\n",
    "# Call the function using the existing df\n",
    "means_df = filter_and_compare_activity(merged_dfx1, day_pulse, day_pre_pulse, start_hour, end_hour)\n",
    "print(means_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20aee70-d3fd-411a-9e54-96c7a2dbd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_compare_activity(df, day_pulse, day_pre_pulse, start_hour, end_hour):\n",
    "    # Get the unique dates for the specified days\n",
    "    pre_pulse_date = df.loc[df['Day'] == day_pre_pulse, 'Time'].dt.date.unique()[0]\n",
    "    pulse_date = df.loc[df['Day'] == day_pulse, 'Time'].dt.date.unique()[0]\n",
    "    \n",
    "    # Construct start and end times with the correct dates\n",
    "    start_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {start_hour}\")\n",
    "    end_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {end_hour}\")\n",
    "    start_time_pulse = pd.to_datetime(f\"{pulse_date} {start_hour}\")\n",
    "    end_time_pulse = pd.to_datetime(f\"{pulse_date} {end_hour}\")\n",
    "    \n",
    "    # Filter the days\n",
    "    day_pre = df.loc[df['Day'] == day_pre_pulse]\n",
    "    day_pulse = df.loc[df['Day'] == day_pulse]\n",
    "    \n",
    "    # Filter the time range for the specified days\n",
    "    day_pre_filtered = day_pre[(day_pre['Time'] >= start_time_pre_pulse) & (day_pre['Time'] <= end_time_pre_pulse)]\n",
    "    day_pulse_filtered = day_pulse[(day_pulse['Time'] >= start_time_pulse) & (day_pulse['Time'] <= end_time_pulse)]\n",
    "    \n",
    "    # Initialize a list to store mean activity data for each spider\n",
    "    spider_means = []\n",
    "    \n",
    "    # Loop through each spider column\n",
    "    spider_columns = [col for col in df.columns if col.startswith('Sp')]\n",
    "    \n",
    "    # Calculate the number of rows and columns for the grid\n",
    "    num_spiders = len(spider_columns)\n",
    "    num_cols = 3  # You can adjust this value based on how many columns you want in the grid\n",
    "    num_rows = (num_spiders + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array to easily index it\n",
    "    \n",
    "    for idx, spider_col in enumerate(spider_columns):\n",
    "        # Filter for the specific spider column\n",
    "        spider_day_pre = day_pre_filtered[spider_col]\n",
    "        spider_day_pulse = day_pulse_filtered[spider_col]\n",
    "        \n",
    "        # Calculate the mean activity\n",
    "        mean_day_pre = spider_day_pre.mean()\n",
    "        mean_day_pulse = spider_day_pulse.mean()\n",
    "        \n",
    "        # Append the results to the spider_means list\n",
    "        spider_means.append((spider_col, mean_day_pre, mean_day_pulse))\n",
    "        \n",
    "        # Plot the results for each spider in the grid\n",
    "        ax = axes[idx]\n",
    "        days = ['Pre-pulse day', '2-hour pulse']\n",
    "        means = [mean_day_pre, mean_day_pulse]\n",
    "        \n",
    "        ax.bar(days, means)\n",
    "        ax.set_title(f'{spider_col}', fontsize=10)\n",
    "        ax.set_ylabel('Average activity', fontsize=8)\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(days, fontsize=8)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "    \n",
    "    # Remove any empty subplots\n",
    "    for j in range(idx + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    # Find the maximum mean activity across all spiders\n",
    "    max_mean_activity = max([mean for _, mean_pre, mean_pulse in spider_means for mean in (mean_pre, mean_pulse)])\n",
    "    \n",
    "    # Set the same y-axis range for all subplots\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(0, max_mean_activity)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a DataFrame to store the means for all spiders\n",
    "    means_df = pd.DataFrame(spider_means, columns=['Spider', 'Mean Pre-pulse Activity', 'Mean Pulse Activity'])\n",
    "    \n",
    "    return means_df\n",
    "\n",
    "# Example usage\n",
    "# Define the parameters\n",
    "day_pulse = 5  # The day when the pulse occurred\n",
    "day_pre_pulse = 4  # The day before the pulse\n",
    "start_hour = '14:00:00'  # Replace with the desired start hour\n",
    "end_hour = '16:00:00'  # Replace with the desired end hour\n",
    "\n",
    "# Ensure 'Time' is in datetime format\n",
    "merged_dfx1['Time'] = pd.to_datetime(merged_dfx1['Time'])\n",
    "\n",
    "# Call the function using the existing df\n",
    "means_df = filter_and_compare_activity(merged_dfx1, day_pulse, day_pre_pulse, start_hour, end_hour)\n",
    "print(means_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ab395-d9db-4fd4-9dfb-94d9efcaa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for a single day \n",
    "day1 = df[df['Day'] == 1]\n",
    "count_mov = day1.filter(like=\"Sp\")  \n",
    "sum_count = count_mov.sum(axis=0) \n",
    "threshold = 0\n",
    "filter_sum = sum_count > threshold \n",
    "columns_to_keep = filter_sum[filter_sum].index  \n",
    "additional_columns = df.columns[:3]\n",
    "all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "filtered_df = day1[all_columns_to_keep]\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6474ca7-78aa-468d-a542-e43538c7c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering for all days \n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0\n",
    "additional_columns = df.columns[:3]\n",
    "filtered_dfs = []\n",
    "\n",
    "for day in range(1, 9):  \n",
    "    day_df = df[df['Day'] == day] \n",
    "    count_mov = day_df.filter(like=\"Sp\")  \n",
    "    x = count_mov.sum(axis=0)  \n",
    "    z = x > threshold  \n",
    "    columns_to_keep = z[z].index \n",
    "    \n",
    "    all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "    filtered_df = day_df[all_columns_to_keep]\n",
    "    filtered_dfs.append(filtered_df)\n",
    "\n",
    "merged_df = pd.concat(filtered_dfs)\n",
    "merged_df1 = merged_df.dropna(axis=1)\n",
    "display(merged_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f9c0f-f31f-466f-b458-ce1ed184969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter \n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_merge(df, threshold=0):\n",
    "    additional_columns = df.columns[:3]\n",
    "    filtered_dfs = []\n",
    "\n",
    "    for day in range(1, 9):  \n",
    "        day_df = df[df['Day'] == day] \n",
    "        count_mov = day_df.filter(like=\"Sp\")  \n",
    "        x = count_mov.sum(axis=0)  \n",
    "        z = x > threshold  \n",
    "        columns_to_keep = z[z].index \n",
    "        \n",
    "        all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "        filtered_df = day_df[all_columns_to_keep]\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    merged_df = pd.concat(filtered_dfs)\n",
    "    merged_df1 = merged_df.dropna(axis=1)\n",
    "    \n",
    "    return merged_df1\n",
    "    \n",
    "merged_df = filter_and_merge(df)\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fbd7d-b8d4-4f04-9664-a6c9ec434a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#have the dataframes all at once \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "files = ['Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt', 'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt', 'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae5713-2b09-40ac-bff8-84c8bbbe935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_and_merge(df, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5c62c-688b-4e82-8890-7710cc0b85f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#have the dataframes all at once \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "files = ['Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt', 'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt', 'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765414ac-7781-49f8-b87f-c09796ef0ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#have the dataframes all at once \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "files = ['Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt', 'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt', 'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2acd2e-2e1d-459b-ba67-f8dbc9fa4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "def filter_and_merge(dataframes, threshold=0):\n",
    "    merged_filtered_dfs = []\n",
    "    for name, df in dataframes.items():\n",
    "        additional_columns = df.columns[:3]\n",
    "        filtered_dfs = []\n",
    "\n",
    "        for day in range(1, 9):  \n",
    "            day_df = df[df['Day'] == day] \n",
    "            count_mov = day_df.filter(like=\"Sp\")  \n",
    "            x = count_mov.sum(axis=0)  \n",
    "            z = x > threshold  \n",
    "            columns_to_keep = z[z].index \n",
    "\n",
    "            all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "            filtered_df = day_df[all_columns_to_keep]\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "        merged_df = pd.concat(filtered_dfs)\n",
    "        merged_df1 = merged_df.dropna(axis=1)\n",
    "        merged_filtered_dfs.append(merged_df1)\n",
    "    \n",
    "    final_merged_df = pd.concat(merged_filtered_dfs)\n",
    "    return final_merged_df\n",
    "\n",
    "files = [\n",
    "    'Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt',\n",
    "    'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt',\n",
    "    'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt',\n",
    "    'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt'\n",
    "]\n",
    "\n",
    "dataframes = process_files(files)\n",
    "\n",
    "final_merged_df = filter_and_merge(dataframes, threshold=0)\n",
    "\n",
    "display(final_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3951263-4a96-49d2-88e2-6565d9a5f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "def filter_and_merge(dataframes, threshold=0):\n",
    "    filtered_dataframes = {}\n",
    "    for name, df in dataframes.items():\n",
    "        additional_columns = df.columns[:3]\n",
    "        filtered_dfs = []\n",
    "\n",
    "        for day in range(1, 9):  \n",
    "            day_df = df[df['Day'] == day] \n",
    "            count_mov = day_df.filter(like=\"Sp\")  \n",
    "            x = count_mov.sum(axis=0)  \n",
    "            z = x > threshold  \n",
    "            columns_to_keep = z[z].index \n",
    "\n",
    "            all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "            filtered_df = day_df[all_columns_to_keep]\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "        merged_df = pd.concat(filtered_dfs)\n",
    "        merged_df1 = merged_df.dropna(axis=1)\n",
    "        filtered_dataframes[name] = merged_df1\n",
    "    \n",
    "    return filtered_dataframes\n",
    "\n",
    "# List of files to process\n",
    "files = [\n",
    "    'Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt',\n",
    "    'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt',\n",
    "    'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt',\n",
    "    'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt'\n",
    "]\n",
    "\n",
    "dataframes = process_files(files)\n",
    "\n",
    "filtered_dataframes = filter_and_merge(dataframes, threshold=0)\n",
    "\n",
    "for name, df in filtered_dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413cc94-fc03-482e-9ae1-89834b7a0ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f147e-0be3-4e36-a2ab-4cfaec3ea82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
