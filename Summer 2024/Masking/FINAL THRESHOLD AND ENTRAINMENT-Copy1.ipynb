{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 3,
>>>>>>> 36c0ec92f85795926dc24920aa975990675f56e6
   "id": "2f86cd97-3c73-4bb3-94af-2b1abe9f0d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Steatoda A masking 02 pm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
<<<<<<< HEAD
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     col_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSp\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSteatoda A masking 02 pm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
=======
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     col_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSp\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSteatoda A masking 02 pm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
>>>>>>> 36c0ec92f85795926dc24920aa975990675f56e6
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Steatoda A masking 02 pm'"
     ]
    }
   ],
   "source": [
    "#liz stacy ethan code\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "\n",
    "for i in range(1, 33):\n",
    "    col_names.append(f\"Sp{i}\")\n",
    "\n",
    "file = 'Steatoda A masking 02 pm'\n",
    "\n",
    "df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "df = df.set_index('Index')\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "\n",
    "#df.to_csv('steatodaA.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158aa70-a5ef-4243-bded-9e2d2336ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter threshold\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_merge(df, threshold=0):\n",
    "    additional_columns = df.columns[:3]\n",
    "    filtered_dfs = []\n",
    "\n",
    "    for day in range(1, 9):  \n",
    "        day_df = df[df['Day'] == day] \n",
    "        count_mov = day_df.filter(like=\"Sp\")  \n",
    "        x = count_mov.sum(axis=0)  \n",
    "        z = x > threshold  \n",
    "        columns_to_keep = z[z].index \n",
    "        \n",
    "        all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "        filtered_df = day_df[all_columns_to_keep]\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    merged_df = pd.concat(filtered_dfs)\n",
    "    merged_df1 = merged_df.dropna(axis=1)\n",
    "    \n",
    "    return merged_df1\n",
    "    \n",
    "merged_df = filter_and_merge(df)\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd9d56-9a42-4145-8471-dac4c49e13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def entrainment(data, column):\n",
    "    if column not in data.columns:\n",
    "        return False\n",
    "    \n",
    "    dflight = data[data['Light'] == 1][column]\n",
    "    dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "    lightmean = np.mean(dflight)\n",
    "    darkmean = np.mean(dfdark)\n",
    "    \n",
    "    if darkmean == 0:\n",
    "        return False\n",
    "    \n",
    "    diff = lightmean / darkmean\n",
    "    return diff > 0.25\n",
    "\n",
    "spiders = [\"Sp\"+str(i) for i in range(1, 33)]\n",
    "\n",
    "entrainment_results = []\n",
    "\n",
    "for spider_column in spiders:\n",
    "    if spider_column in merged_df.columns:  # Check if the column exists\n",
    "        entrainment_result = entrainment(merged_df, spider_column)\n",
    "        entrainment_results.append((spider_column, entrainment_result))\n",
    "\n",
    "results_df = pd.DataFrame(entrainment_results, columns=['Spider', 'Entrained'])\n",
    "\n",
    "# Get the list of spiders that have entrainment True\n",
    "entrained_spiders = results_df[results_df['Entrained'] == True]['Spider'].tolist()\n",
    "\n",
    "print(\"Results DataFrame:\")\n",
    "print(results_df)\n",
    "print(\"\\nList of spiders with entrainment True:\")\n",
    "print(entrained_spiders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf7ba4-018c-42e6-b067-88a6ac6ebf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = []\n",
    "\n",
    "additional_columns = merged_df.columns[:3]  # Assuming the first three columns are additional columns\n",
    "columns_to_keep = entrained_spiders\n",
    "        \n",
    "all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "filtered_df = merged_df[all_columns_to_keep]  # Use merged_df here, not entrained_spiders\n",
    "\n",
    "finaldf.append(filtered_df)\n",
    "\n",
    "merged_dfx = pd.concat(finaldf)\n",
    "merged_dfx1 = merged_dfx.dropna(axis=1)  # Use merged_dfx here, not merged_df\n",
    "\n",
    "display(merged_dfx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789c821-fbca-45a7-bc97-7488749525b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter day 5 and day 4 (the nile research did day the day of pulse and the day before)\n",
    "#I can also filter all days without pulse and average them and compare with the day WITH pulse \n",
    "dayfour = df.loc[df['Day'] == 4]\n",
    "dayfive = df.loc[df['Day'] == 5]\n",
    "dayfourfive = pd.concat([dayfour, dayfive])\n",
    "dayfourfive\n",
    "# filter time (2 pm - 4 pm in this case) - fix this because is about 2 hours but not exactly 2 hours (look if light or dark)\n",
    "index = dayfourfive.loc[(dayfourfive == '2024-03-23 14:00:00').any(axis=1)].index[0]\n",
    "index1 = dayfourfive.loc[(dayfourfive == '2024-03-23 16:00:00').any(axis=1)].index[0]\n",
    "\n",
    "index2 = dayfourfive.loc[(dayfourfive == '2024-03-24 14:00:00').any(axis=1)].index[0]\n",
    "index3 = dayfourfive.loc[(dayfourfive == '2024-03-24 16:00:00').any(axis=1)].index[0]\n",
    "\n",
    "dayfourslice = dayfourfive.loc[index:index1, :]\n",
    "dayfiveslice = dayfourfive.loc[index2:index3, :]\n",
    "\n",
    "twotofourslice = pd.concat([dayfourslice, dayfiveslice])\n",
    "# filter individual spider \n",
    "spider1_day4 = dayfourslice['Sp21']\n",
    "spider1_day5 = dayfiveslice['Sp21']\n",
    "\n",
    "# average it out for both pulse and no pulse \n",
    "meanday4 = spider1_day4.mean()\n",
    "meanday5 = spider1_day5.mean()\n",
    "days = ['Pre-pulse day', '2-hour pulse']\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(3,3))\n",
    "\n",
    "plt.bar(days, [meanday4, meanday5]) \n",
    "\n",
    "plt.suptitle('Comparison in activity with and without the 2 hour pulse', fontsize=8)\n",
    "plt.ylabel('Average activity between 2 pm and 4 pm', fontsize=8)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66ad28-4a48-4223-b6d7-8511f19d0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_compare_activity(df, spider_col, day_pulse, day_pre_pulse, start_hour, end_hour):\n",
    "    pre_pulse_date = df.loc[df['Day'] == day_pre_pulse, 'Time'].dt.date.unique()[0]\n",
    "    pulse_date = df.loc[df['Day'] == day_pulse, 'Time'].dt.date.unique()[0]\n",
    "    \n",
    "    start_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {start_hour}\")\n",
    "    end_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {end_hour}\")\n",
    "    start_time_pulse = pd.to_datetime(f\"{pulse_date} {start_hour}\")\n",
    "    end_time_pulse = pd.to_datetime(f\"{pulse_date} {end_hour}\")\n",
    "    \n",
    "    day_pre = df.loc[df['Day'] == day_pre_pulse]\n",
    "    day_pulse = df.loc[df['Day'] == day_pulse]\n",
    "    \n",
    "    day_pre_filtered = day_pre[(day_pre['Time'] >= start_time_pre_pulse) & (day_pre['Time'] <= end_time_pre_pulse)]\n",
    "    day_pulse_filtered = day_pulse[(day_pulse['Time'] >= start_time_pulse) & (day_pulse['Time'] <= end_time_pulse)]\n",
    "    \n",
    "    spider_day_pre = day_pre_filtered[spider_col]\n",
    "    spider_day_pulse = day_pulse_filtered[spider_col]\n",
    "    \n",
    "    mean_day_pre = spider_day_pre.mean()\n",
    "    mean_day_pulse = spider_day_pulse.mean()\n",
    "    \n",
    "    means_df = pd.DataFrame({\n",
    "        'Day': ['Pre-pulse day', '2-hour pulse'],\n",
    "        'Mean Activity': [mean_day_pre, mean_day_pulse]\n",
    "    })\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.bar(means_df['Day'], means_df['Mean Activity'])\n",
    "    plt.suptitle('Comparison in activity with and without the 2-hour pulse', fontsize=8)\n",
    "    plt.ylabel('Average activity between {} and {}'.format(start_hour, end_hour), fontsize=6)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.show()\n",
    "    \n",
    "    return means_df\n",
    "\n",
    "spider_col = 'Sp9'  \n",
    "day_pulse = 5 \n",
    "day_pre_pulse = 4  \n",
    "start_hour = '14:00:00' \n",
    "end_hour = '16:00:00'  \n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "means_df = filter_and_compare_activity(df, spider_col, day_pulse, day_pre_pulse, start_hour, end_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f06e9-e7ae-4f17-aac6-cf00ece9faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_compare_activity(df, day_pulse, day_pre_pulse, start_hour, end_hour):\n",
    "    # Get the unique dates for the specified days\n",
    "    pre_pulse_date = df.loc[df['Day'] == day_pre_pulse, 'Time'].dt.date.unique()[0]\n",
    "    pulse_date = df.loc[df['Day'] == day_pulse, 'Time'].dt.date.unique()[0]\n",
    "    \n",
    "    # Construct start and end times with the correct dates\n",
    "    start_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {start_hour}\")\n",
    "    end_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {end_hour}\")\n",
    "    start_time_pulse = pd.to_datetime(f\"{pulse_date} {start_hour}\")\n",
    "    end_time_pulse = pd.to_datetime(f\"{pulse_date} {end_hour}\")\n",
    "    \n",
    "    # Filter the days\n",
    "    day_pre = df.loc[df['Day'] == day_pre_pulse]\n",
    "    day_pulse = df.loc[df['Day'] == day_pulse]\n",
    "    \n",
    "    # Filter the time range for the specified days\n",
    "    day_pre_filtered = day_pre[(day_pre['Time'] >= start_time_pre_pulse) & (day_pre['Time'] <= end_time_pre_pulse)]\n",
    "    day_pulse_filtered = day_pulse[(day_pulse['Time'] >= start_time_pulse) & (day_pulse['Time'] <= end_time_pulse)]\n",
    "    \n",
    "    # Initialize a list to store mean activity data for each spider\n",
    "    spider_means = []\n",
    "    \n",
    "    # Loop through each spider column\n",
    "    spider_columns = [col for col in df.columns if col.startswith('Sp')]\n",
    "    \n",
    "    # Calculate the number of rows and columns for the grid\n",
    "    num_spiders = len(spider_columns)\n",
    "    num_cols = 3  # You can adjust this value based on how many columns you want in the grid\n",
    "    num_rows = (num_spiders + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array to easily index it\n",
    "    \n",
    "    for idx, spider_col in enumerate(spider_columns):\n",
    "        # Filter for the specific spider column\n",
    "        spider_day_pre = day_pre_filtered[spider_col]\n",
    "        spider_day_pulse = day_pulse_filtered[spider_col]\n",
    "        \n",
    "        # Calculate the mean activity\n",
    "        mean_day_pre = spider_day_pre.mean()\n",
    "        mean_day_pulse = spider_day_pulse.mean()\n",
    "        \n",
    "        # Append the results to the spider_means list\n",
    "        spider_means.append((spider_col, mean_day_pre, mean_day_pulse))\n",
    "        \n",
    "        # Plot the results for each spider in the grid\n",
    "        ax = axes[idx]\n",
    "        days = ['Pre-pulse day', '2-hour pulse']\n",
    "        means = [mean_day_pre, mean_day_pulse]\n",
    "        \n",
    "        ax.bar(days, means)\n",
    "        ax.set_title(f'{spider_col}', fontsize=10)\n",
    "        ax.set_ylabel('Average activity', fontsize=8)\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(days, fontsize=8)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "    \n",
    "    # Remove any empty subplots\n",
    "    for j in range(idx + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a DataFrame to store the means for all spiders\n",
    "    means_df = pd.DataFrame(spider_means, columns=['Spider', 'Mean Pre-pulse Activity', 'Mean Pulse Activity'])\n",
    "    \n",
    "    return means_df\n",
    "\n",
    "# Example usage\n",
    "# Define the parameters\n",
    "day_pulse = 5  # The day when the pulse occurred\n",
    "day_pre_pulse = 4  # The day before the pulse\n",
    "start_hour = '14:00:00'  # Replace with the desired start hour\n",
    "end_hour = '16:00:00'  # Replace with the desired end hour\n",
    "\n",
    "# Ensure 'Time' is in datetime format\n",
    "merged_dfx1['Time'] = pd.to_datetime(merged_dfx1['Time'])\n",
    "\n",
    "# Call the function using the existing df\n",
    "means_df = filter_and_compare_activity(merged_dfx1, day_pulse, day_pre_pulse, start_hour, end_hour)\n",
    "print(means_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20aee70-d3fd-411a-9e54-96c7a2dbd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_compare_activity(df, day_pulse, day_pre_pulse, start_hour, end_hour):\n",
    "    # Get the unique dates for the specified days\n",
    "    pre_pulse_date = df.loc[df['Day'] == day_pre_pulse, 'Time'].dt.date.unique()[0]\n",
    "    pulse_date = df.loc[df['Day'] == day_pulse, 'Time'].dt.date.unique()[0]\n",
    "    \n",
    "    # Construct start and end times with the correct dates\n",
    "    start_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {start_hour}\")\n",
    "    end_time_pre_pulse = pd.to_datetime(f\"{pre_pulse_date} {end_hour}\")\n",
    "    start_time_pulse = pd.to_datetime(f\"{pulse_date} {start_hour}\")\n",
    "    end_time_pulse = pd.to_datetime(f\"{pulse_date} {end_hour}\")\n",
    "    \n",
    "    # Filter the days\n",
    "    day_pre = df.loc[df['Day'].between(day_pre_pulse - 2, day_pre_pulse)]  # Adjusted to pull days 2 through 4\n",
    "    day_pulse = df.loc[df['Day'] == day_pulse]\n",
    "    \n",
    "    # Filter the time range for the specified days\n",
    "    day_pre_filtered = day_pre[(day_pre['Time'] >= start_time_pre_pulse) & (day_pre['Time'] <= end_time_pre_pulse)]\n",
    "    day_pulse_filtered = day_pulse[(day_pulse['Time'] >= start_time_pulse) & (day_pulse['Time'] <= end_time_pulse)]\n",
    "    \n",
    "    # Initialize a list to store mean activity data for each spider\n",
    "    spider_means = []\n",
    "    \n",
    "    # Loop through each spider column\n",
    "    spider_columns = [col for col in df.columns if col.startswith('Sp')]\n",
    "    \n",
    "    # Calculate the number of rows and columns for the grid\n",
    "    num_spiders = len(spider_columns)\n",
    "    num_cols = 3  # You can adjust this value based on how many columns you want in the grid\n",
    "    num_rows = (num_spiders + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array to easily index it\n",
    "    \n",
    "    for idx, spider_col in enumerate(spider_columns):\n",
    "        # Filter for the specific spider column\n",
    "        spider_day_pre = day_pre_filtered[spider_col]\n",
    "        spider_day_pulse = day_pulse_filtered[spider_col]\n",
    "        \n",
    "        # Calculate the mean activity and standard error of the mean\n",
    "        mean_day_pre = spider_day_pre.mean()\n",
    "        mean_day_pulse = spider_day_pulse.mean()\n",
    "        sem_day_pre = spider_day_pre.sem()\n",
    "        sem_day_pulse = spider_day_pulse.sem()\n",
    "        \n",
    "        # Append the results to the spider_means list\n",
    "        spider_means.append((spider_col, mean_day_pre, mean_day_pulse))\n",
    "        \n",
    "        # Plot the results for each spider in the grid\n",
    "        ax = axes[idx]\n",
    "        days = ['Pre-pulse day', '2-hour pulse']\n",
    "        means = [mean_day_pre, mean_day_pulse]\n",
    "        errors = [sem_day_pre, sem_day_pulse]  # Standard error of the mean\n",
    "        \n",
    "        ax.bar(days, means, yerr=errors, capsize=5)\n",
    "        ax.set_title(f'{spider_col}', fontsize=10)\n",
    "        ax.set_ylabel('Average activity (Cnts/min)', fontsize=8)\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(days, fontsize=8)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "    \n",
    "    # Remove any empty subplots\n",
    "    for j in range(idx + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    # Find the maximum mean activity across all spiders\n",
    "    max_mean_activity = max([mean for _, mean_pre, mean_pulse in spider_means for mean in (mean_pre, mean_pulse)])\n",
    "    \n",
    "    # Set the same y-axis range for all subplots\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(0, 0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a DataFrame to store the means for all spiders\n",
    "    means_df = pd.DataFrame(spider_means, columns=['Spider', 'Mean Pre-pulse Activity', 'Mean Pulse Activity'])\n",
    "    \n",
    "    return means_df\n",
    "\n",
    "# Example usage\n",
    "# Define the parameters\n",
    "day_pulse = 5  # The day when the pulse occurred\n",
    "day_pre_pulse = 4  # The day before the pulse\n",
    "start_hour = '14:00:00'  # Replace with the desired start hour\n",
    "end_hour = '16:00:00'  # Replace with the desired end hour\n",
    "\n",
    "# Ensure 'Time' is in datetime format\n",
    "merged_dfx1['Time'] = pd.to_datetime(merged_dfx1['Time'])\n",
    "\n",
    "# Call the function using the existing df\n",
    "means_df = filter_and_compare_activity(merged_dfx1, day_pulse, day_pre_pulse, start_hour, end_hour)\n",
    "print(means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ab395-d9db-4fd4-9dfb-94d9efcaa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for a single day \n",
    "day1 = df[df['Day'] == 1]\n",
    "count_mov = day1.filter(like=\"Sp\")  \n",
    "sum_count = count_mov.sum(axis=0) \n",
    "threshold = 0\n",
    "filter_sum = sum_count > threshold \n",
    "columns_to_keep = filter_sum[filter_sum].index  \n",
    "additional_columns = df.columns[:3]\n",
    "all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "filtered_df = day1[all_columns_to_keep]\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6474ca7-78aa-468d-a542-e43538c7c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering for all days \n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0\n",
    "additional_columns = df.columns[:3]\n",
    "filtered_dfs = []\n",
    "\n",
    "for day in range(1, 9):  \n",
    "    day_df = df[df['Day'] == day] \n",
    "    count_mov = day_df.filter(like=\"Sp\")  \n",
    "    x = count_mov.sum(axis=0)  \n",
    "    z = x > threshold  \n",
    "    columns_to_keep = z[z].index \n",
    "    \n",
    "    all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "    filtered_df = day_df[all_columns_to_keep]\n",
    "    filtered_dfs.append(filtered_df)\n",
    "\n",
    "merged_df = pd.concat(filtered_dfs)\n",
    "merged_df1 = merged_df.dropna(axis=1)\n",
    "display(merged_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f9c0f-f31f-466f-b458-ce1ed184969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter \n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_merge(df, threshold=0):\n",
    "    additional_columns = df.columns[:3]\n",
    "    filtered_dfs = []\n",
    "\n",
    "    for day in range(1, 9):  \n",
    "        day_df = df[df['Day'] == day] \n",
    "        count_mov = day_df.filter(like=\"Sp\")  \n",
    "        x = count_mov.sum(axis=0)  \n",
    "        z = x > threshold  \n",
    "        columns_to_keep = z[z].index \n",
    "        \n",
    "        all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "        filtered_df = day_df[all_columns_to_keep]\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    merged_df = pd.concat(filtered_dfs)\n",
    "    merged_df1 = merged_df.dropna(axis=1)\n",
    "    \n",
    "    return merged_df1\n",
    "    \n",
    "merged_df = filter_and_merge(df)\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fbd7d-b8d4-4f04-9664-a6c9ec434a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#have the dataframes all at once \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "files = ['Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt', 'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt', 'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae5713-2b09-40ac-bff8-84c8bbbe935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_and_merge(df, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5c62c-688b-4e82-8890-7710cc0b85f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#have the dataframes all at once \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "files = ['Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt', 'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt', 'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765414ac-7781-49f8-b87f-c09796ef0ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#have the dataframes all at once \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "files = ['Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt', 'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt', 'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2acd2e-2e1d-459b-ba67-f8dbc9fa4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "def filter_and_merge(dataframes, threshold=0):\n",
    "    merged_filtered_dfs = []\n",
    "    for name, df in dataframes.items():\n",
    "        additional_columns = df.columns[:3]\n",
    "        filtered_dfs = []\n",
    "\n",
    "        for day in range(1, 9):  \n",
    "            day_df = df[df['Day'] == day] \n",
    "            count_mov = day_df.filter(like=\"Sp\")  \n",
    "            x = count_mov.sum(axis=0)  \n",
    "            z = x > threshold  \n",
    "            columns_to_keep = z[z].index \n",
    "\n",
    "            all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "            filtered_df = day_df[all_columns_to_keep]\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "        merged_df = pd.concat(filtered_dfs)\n",
    "        merged_df1 = merged_df.dropna(axis=1)\n",
    "        merged_filtered_dfs.append(merged_df1)\n",
    "    \n",
    "    final_merged_df = pd.concat(merged_filtered_dfs)\n",
    "    return final_merged_df\n",
    "\n",
    "files = [\n",
    "    'Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt',\n",
    "    'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt',\n",
    "    'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt',\n",
    "    'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt'\n",
    "]\n",
    "\n",
    "dataframes = process_files(files)\n",
    "\n",
    "final_merged_df = filter_and_merge(dataframes, threshold=0)\n",
    "\n",
    "display(final_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3951263-4a96-49d2-88e2-6565d9a5f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    \n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "def filter_and_merge(dataframes, threshold=0):\n",
    "    filtered_dataframes = {}\n",
    "    for name, df in dataframes.items():\n",
    "        additional_columns = df.columns[:3]\n",
    "        filtered_dfs = []\n",
    "\n",
    "        for day in range(1, 9):  \n",
    "            day_df = df[df['Day'] == day] \n",
    "            count_mov = day_df.filter(like=\"Sp\")  \n",
    "            x = count_mov.sum(axis=0)  \n",
    "            z = x > threshold  \n",
    "            columns_to_keep = z[z].index \n",
    "\n",
    "            all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "            filtered_df = day_df[all_columns_to_keep]\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "        merged_df = pd.concat(filtered_dfs)\n",
    "        merged_df1 = merged_df.dropna(axis=1)\n",
    "        filtered_dataframes[name] = merged_df1\n",
    "    \n",
    "    return filtered_dataframes\n",
    "\n",
    "# List of files to process\n",
    "files = [\n",
    "    'Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt',\n",
    "    'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt',\n",
    "    'Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt',\n",
    "    'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt'\n",
    "]\n",
    "\n",
    "dataframes = process_files(files)\n",
    "\n",
    "filtered_dataframes = filter_and_merge(dataframes, threshold=0)\n",
    "\n",
    "for name, df in filtered_dataframes.items():\n",
    "    print(f\"{name}:\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413cc94-fc03-482e-9ae1-89834b7a0ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f147e-0be3-4e36-a2ab-4cfaec3ea82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
