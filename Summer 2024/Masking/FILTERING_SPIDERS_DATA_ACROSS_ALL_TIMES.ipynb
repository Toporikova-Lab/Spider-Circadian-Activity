{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14994d2-3d78-4231-a767-95040e2ced19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spiders in group A that have data across all times and are entrained are: ['Sp4', 'Sp9', 'Sp10', 'Sp12', 'Sp14', 'Sp15', 'Sp19', 'Sp21']\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# def process_file(file):\n",
    "#     col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "#     for i in range(1, 33):\n",
    "#         col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "#     df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "#     df = df.set_index('Index')\n",
    "#     df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "#     df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "#     month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "#     df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "#     df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "#     df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "#     df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "#                                      month=df['Date'].dt.month,\n",
    "#                                      day=df['Date'].dt.day,\n",
    "#                                      hour=df['Time'].dt.hour,\n",
    "#                                      minute=df['Time'].dt.minute,\n",
    "#                                      second=df['Time'].dt.second))\n",
    "\n",
    "#     df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "#     day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "#     df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def process_files(files):\n",
    "#     dataframes = {}\n",
    "#     for idx, file in enumerate(files, start=1):\n",
    "#         df = process_file(file)\n",
    "#         dataframes[f'df{idx}'] = df\n",
    "#     return dataframes\n",
    "\n",
    "# def filter_and_merge(dataframes, threshold=0):\n",
    "#     merged_filtered_dfs = []\n",
    "#     for name, df in dataframes.items():\n",
    "#         additional_columns = df.columns[:3]\n",
    "#         filtered_dfs = []\n",
    "\n",
    "#         for day in range(1, 9):  \n",
    "#             day_df = df[df['Day'] == day] \n",
    "#             count_mov = day_df.filter(like=\"Sp\")  \n",
    "#             sum_mov = count_mov.sum(axis=0)  \n",
    "#             filter_mov = sum_mov > threshold  \n",
    "#             columns_to_keep = filter_mov[filter_mov].index \n",
    "\n",
    "#             all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "#             filtered_df = day_df[all_columns_to_keep]\n",
    "#             filtered_dfs.append(filtered_df)\n",
    "\n",
    "#         merged_df = pd.concat(filtered_dfs)\n",
    "#         merged_df1 = merged_df.dropna(axis=1)\n",
    "#         merged_filtered_dfs.append(merged_df1)\n",
    "    \n",
    "#     final_merged_df = pd.concat(merged_filtered_dfs)\n",
    "#     return final_merged_df\n",
    "\n",
    "# def entrainment(data, column):\n",
    "#     if column not in data.columns:\n",
    "#         return False\n",
    "    \n",
    "#     dflight = data[data['Light'] == 1][column]\n",
    "#     dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "#     lightmean = np.mean(dflight)\n",
    "#     darkmean = np.mean(dfdark)\n",
    "    \n",
    "#     if darkmean == 0:\n",
    "#         return False\n",
    "    \n",
    "#     diff = lightmean / darkmean\n",
    "#     return diff > 0.25\n",
    "\n",
    "# files = [\n",
    "#     'Steatoda A masking 02 pm.txt', 'Steatoda A masking 10 am.txt',\n",
    "#     'Steatoda A masking 4 am.txt', 'Steatoda A masking midnight.txt'\n",
    "# ]\n",
    "\n",
    "# dataframes = process_files(files)\n",
    "# final_merged_df = filter_and_merge(dataframes, threshold=0)\n",
    "\n",
    "# # Check for entrainment\n",
    "# entrained_spiders = []\n",
    "# for spider in final_merged_df.columns[3:]:  # Skip the first three columns\n",
    "#     if entrainment(final_merged_df, spider):\n",
    "#         entrained_spiders.append(spider)\n",
    "\n",
    "# # Filter the final dataframe to keep only entrained spiders\n",
    "# final_merged_df1 = final_merged_df[['Day', 'Time', 'Light'] + entrained_spiders]\n",
    "# final_merged_df2 = final_merged_df1.dropna(axis='columns')\n",
    "\n",
    "# cols_list = final_merged_df2.columns.tolist()\n",
    "# final_list = cols_list[3:]\n",
    "\n",
    "# # Print the result\n",
    "# print(\"The spiders in group A that have data across all times and are entrained are:\", final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e55613a2-87fc-4fc5-8966-62a14a47b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spiders in group B that have data across all times and are entrained are: ['Sp1', 'Sp3', 'Sp5', 'Sp7', 'Sp12', 'Sp14', 'Sp17', 'Sp18', 'Sp19', 'Sp21', 'Sp22', 'Sp23']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "def filter_and_merge(dataframes, threshold=0):\n",
    "    merged_filtered_dfs = []\n",
    "    for name, df in dataframes.items():\n",
    "        additional_columns = df.columns[:3]\n",
    "        filtered_dfs = []\n",
    "\n",
    "        for day in range(1, 9):  \n",
    "            day_df = df[df['Day'] == day] \n",
    "            count_mov = day_df.filter(like=\"Sp\")  \n",
    "            sum_mov = count_mov.sum(axis=0)  \n",
    "            filter_mov = sum_mov > threshold  \n",
    "            columns_to_keep = filter_mov[filter_mov].index \n",
    "\n",
    "            all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "            filtered_df = day_df[all_columns_to_keep]\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "        merged_df = pd.concat(filtered_dfs)\n",
    "        merged_df1 = merged_df.dropna(axis=1)\n",
    "        merged_filtered_dfs.append(merged_df1)\n",
    "    \n",
    "    final_merged_df = pd.concat(merged_filtered_dfs)\n",
    "    return final_merged_df\n",
    "\n",
    "def entrainment(data, column):\n",
    "    dflight = data[data['Light'] == 1][column]\n",
    "    dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "    lightmean = np.mean(dflight)\n",
    "    darkmean = np.mean(dfdark)\n",
    "    diff = lightmean / darkmean\n",
    "    \n",
    "    return diff > 0.25\n",
    "\n",
    "files = ['Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "final_merged_df = filter_and_merge(dataframes, threshold=0)\n",
    "\n",
    "entrained_spiders = []\n",
    "for spider in final_merged_df.columns[3:]:\n",
    "    if entrainment(final_merged_df, spider):\n",
    "        entrained_spiders.append(spider)\n",
    "\n",
    "final_merged_df1 = final_merged_df[['Day', 'Time', 'Light'] + entrained_spiders]\n",
    "final_merged_df2 = final_merged_df1.dropna(axis='columns')\n",
    "\n",
    "cols_list = final_merged_df2.columns.tolist()\n",
    "final_list = cols_list[3:]\n",
    "\n",
    "print(\"The spiders in group B that have data across all times and are entrained are:\", final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12c0fcd4-1af6-4b22-8896-4323e67b0a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spiders in group B that have data across all times and are entrained are: ['Sp1', 'Sp3', 'Sp5', 'Sp6', 'Sp7', 'Sp8', 'Sp11', 'Sp12', 'Sp13', 'Sp14', 'Sp15', 'Sp17', 'Sp18', 'Sp19', 'Sp20', 'Sp21', 'Sp22', 'Sp23']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "def filter_and_merge(dataframes, threshold=0):\n",
    "    merged_filtered_dfs = []\n",
    "    for name, df in dataframes.items():\n",
    "        additional_columns = df.columns[:3]\n",
    "        filtered_dfs = []\n",
    "\n",
    "        for day in range(1, 9):  \n",
    "            day_df = df[df['Day'] == day] \n",
    "            count_mov = day_df.filter(like=\"Sp\")  \n",
    "            sum_mov = count_mov.sum(axis=0)  \n",
    "            filter_mov = sum_mov > threshold  \n",
    "            columns_to_keep = filter_mov[filter_mov].index \n",
    "\n",
    "            all_columns_to_keep = list(additional_columns) + list(columns_to_keep)\n",
    "            filtered_df = day_df[all_columns_to_keep]\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "        merged_df = pd.concat(filtered_dfs)\n",
    "        merged_df1 = merged_df.dropna(axis=1, how='all')  # Drop columns that are all NaN\n",
    "        merged_filtered_dfs.append(merged_df1)\n",
    "    \n",
    "    final_merged_df = pd.concat(merged_filtered_dfs)\n",
    "    return final_merged_df\n",
    "\n",
    "def entrainment(data, column):\n",
    "    if column not in data.columns:\n",
    "        return False\n",
    "    \n",
    "    dflight = data[data['Light'] == 1][column]\n",
    "    dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "    lightmean = np.mean(dflight)\n",
    "    darkmean = np.mean(dfdark)\n",
    "    \n",
    "    if darkmean == 0:\n",
    "        return False\n",
    "    \n",
    "    diff = lightmean / darkmean\n",
    "    return diff > 0.25\n",
    "\n",
    "files = ['Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "final_merged_df = filter_and_merge(dataframes, threshold=0)\n",
    "\n",
    "entrained_spiders = []\n",
    "for spider in final_merged_df.columns[3:]:\n",
    "    if entrainment(final_merged_df, spider):\n",
    "        entrained_spiders.append(spider)\n",
    "\n",
    "# Create the final dataframe with only entrained spiders\n",
    "final_merged_df1 = final_merged_df[['Day', 'Time', 'Light'] + entrained_spiders]\n",
    "final_merged_df2 = final_merged_df1.dropna(axis='columns', how='all')  # Ensure no columns with all NaN values are included\n",
    "\n",
    "cols_list = final_merged_df2.columns.tolist()\n",
    "final_list = cols_list[3:]\n",
    "\n",
    "print(\"The spiders in group B that have data across all times and are entrained are:\", final_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab14c4bc-2852-4416-a37b-9db13e9f82b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spiders in group B that have data across all times and are entrained are: ['Sp17', 'Sp5', 'Sp18', 'Sp1', 'Sp7', 'Sp19', 'Sp23', 'Sp3', 'Sp13', 'Sp14', 'Sp11', 'Sp6', 'Sp12', 'Sp21', 'Sp20', 'Sp8', 'Sp22']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    col_names = [\"Index\", \"DateD\", \"DateM\", \"DateY\", \"Time\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\", \"Light\"]\n",
    "    for i in range(1, 33):\n",
    "        col_names.append(f\"Sp{i}\")\n",
    "    \n",
    "    df = pd.read_csv(file, names=col_names, sep='\\s+', header=None)\n",
    "    df = df.set_index('Index')\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "    df = df[df[\"MonStatus\"] == 1]\n",
    "\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6}\n",
    "    df['DateM'] = df['DateM'].str[:3].map(month_map)\n",
    "    df['DateY'] = df['DateY'].apply(lambda x: int(str(20) + str(x)))\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['DateY'], month=df['DateM'], day=df['DateD']), errors='coerce')\n",
    "\n",
    "    df['Time'] = pd.to_datetime(dict(year=df['Date'].dt.year,\n",
    "                                     month=df['Date'].dt.month,\n",
    "                                     day=df['Date'].dt.day,\n",
    "                                     hour=df['Time'].dt.hour,\n",
    "                                     minute=df['Time'].dt.minute,\n",
    "                                     second=df['Time'].dt.second))\n",
    "\n",
    "    df = df.drop([\"DateD\", \"DateM\", \"DateY\", \"Date\", \"MonStatus\", \"Extras\", \"MonN\", \"TubeN\", \"DataType\", \"Unused\"], axis=1)\n",
    "\n",
    "    day_map = {day: idx+1 for idx, day in enumerate(df['Time'].dt.day.unique())}\n",
    "    df.insert(0, 'Day', df['Time'].dt.day.map(day_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_files(files):\n",
    "    dataframes = {}\n",
    "    for idx, file in enumerate(files, start=1):\n",
    "        df = process_file(file)\n",
    "        dataframes[f'df{idx}'] = df\n",
    "    return dataframes\n",
    "\n",
    "def filter_and_identify_spiders(dataframes, threshold=0):\n",
    "    spiders_threshold_met = []\n",
    "    \n",
    "    for name, df in dataframes.items():\n",
    "        filtered_spiders = set()\n",
    "        for day in range(1, 9):  \n",
    "            day_df = df[df['Day'] == day] \n",
    "            count_mov = day_df.filter(like=\"Sp\")  \n",
    "            sum_mov = count_mov.sum(axis=0)  \n",
    "            filter_mov = sum_mov > threshold  \n",
    "            columns_to_keep = filter_mov[filter_mov].index \n",
    "            filtered_spiders.update(columns_to_keep)\n",
    "\n",
    "        spiders_threshold_met.append(filtered_spiders)\n",
    "    \n",
    "    common_spiders = set.intersection(*spiders_threshold_met)\n",
    "    return common_spiders\n",
    "\n",
    "def entrainment(data, column):\n",
    "    dflight = data[data['Light'] == 1][column]\n",
    "    dfdark = data[data['Light'] == 0][column]\n",
    "    \n",
    "    lightmean = np.mean(dflight)\n",
    "    darkmean = np.mean(dfdark)\n",
    "    if darkmean == 0:\n",
    "        return False\n",
    "    \n",
    "    diff = lightmean / darkmean\n",
    "    return diff > 0.25\n",
    "\n",
    "def filter_and_merge(dataframes, common_spiders):\n",
    "    final_filtered_dfs = []\n",
    "    \n",
    "    for name, df in dataframes.items():\n",
    "        filtered_df = df[['Day', 'Time', 'Light'] + list(common_spiders)]\n",
    "        filtered_df = filtered_df.dropna(axis=1, how='all')\n",
    "        final_filtered_dfs.append(filtered_df)\n",
    "    \n",
    "    final_merged_df = pd.concat(final_filtered_dfs)\n",
    "    return final_merged_df\n",
    "\n",
    "files = ['Steatoda B masking 04 pm.txt', 'Steatoda B masking 10 pm.txt', 'Steatoda B masking 12 pm.txt', 'Steatoda B maskng 2am.txt']\n",
    "\n",
    "dataframes = process_files(files)\n",
    "common_spiders = filter_and_identify_spiders(dataframes, threshold=0)\n",
    "final_merged_df = filter_and_merge(dataframes, common_spiders)\n",
    "\n",
    "entrained_spiders = []\n",
    "for spider in common_spiders:\n",
    "    if entrainment(final_merged_df, spider):\n",
    "        entrained_spiders.append(spider)\n",
    "\n",
    "final_merged_df1 = final_merged_df[['Day', 'Time', 'Light'] + entrained_spiders]\n",
    "final_merged_df2 = final_merged_df1.dropna(axis='columns', how='all')\n",
    "\n",
    "cols_list = final_merged_df2.columns.tolist()\n",
    "final_list = cols_list[3:]\n",
    "\n",
    "print(\"The spiders in group B that have data across all times and are entrained are:\", final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93abb009-fdb3-4d9b-a2f9-2d591bd5b301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
